
class Tokenizer():
    def __init__(self):
        pass

    def split_by_character(self, text):
        return list(text)

    def split_by_word(self, text):
        return text.split(" ")